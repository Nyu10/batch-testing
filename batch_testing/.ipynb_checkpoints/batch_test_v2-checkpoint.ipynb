{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Testing Tutorial\n",
    "\n",
    "This tutorial has two roles:\n",
    "\n",
    "1. Be familiar with our code.\n",
    "2. Reproduce the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import time\n",
    "import numba\n",
    "import fast_btk as fbtk\n",
    "import collections\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation\n",
    "\n",
    "The function `data_gen` can generate a population with a certain size and infection rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nehem\\Documents\\programming\\batch-testing\\batch_testing\\fast_btk.py:381: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"data_gen\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function zeros>) found for signature:\n",
      " \n",
      " >>> zeros(Tuple(int64, Literal[int](2)), dtype=Function(<class 'int'>))\n",
      " \n",
      "There are 2 candidate implementations:\n",
      "\u001b[1m  - Of which 2 did not match due to:\n",
      "  Overload of function 'zeros': File: numba\\core\\typing\\npydecl.py: Line 511.\n",
      "    With argument(s): '(UniTuple(int64 x 2), dtype=Function(<class 'int'>))':\u001b[0m\n",
      "\u001b[1m   No match.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: resolving callee type: Function(<built-in function zeros>)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of call at C:\\Users\\nehem\\Documents\\programming\\batch-testing\\batch_testing\\fast_btk.py (396)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 396:\u001b[0m\n",
      "\u001b[1mdef data_gen(size, p):\n",
      "    <source elided>\n",
      "    random_table = np.random.binomial(size = size, p = p, n = 1)\n",
      "\u001b[1m    test_array = np.zeros((size, 2), dtype = np.int)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Users\\nehem\\Documents\\programming\\batch-testing\\batch_testing\\fast_btk.py:381: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"data_gen\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 397:\u001b[0m\n",
      "\u001b[1mdef data_gen(size, p):\n",
      "    <source elided>\n",
      "    test_array = np.zeros((size, 2), dtype = np.int)\n",
      "\u001b[1m    for i in range(size):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "c:\\users\\nehem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"data_gen\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 395:\u001b[0m\n",
      "\u001b[1mdef data_gen(size, p):\n",
      "    <source elided>\n",
      "    #print(np.random.get_state()[1][0])\n",
      "\u001b[1m    random_table = np.random.binomial(size = size, p = p, n = 1)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\users\\nehem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 395:\u001b[0m\n",
      "\u001b[1mdef data_gen(size, p):\n",
      "    <source elided>\n",
      "    #print(np.random.get_state()[1][0])\n",
      "\u001b[1m    random_table = np.random.binomial(size = size, p = p, n = 1)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\nehem\\AppData\\Local\\Temp/ipykernel_8516/1271206354.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fbtk.data_gen(size = 10, p = 0.1)\n",
      "c:\\users\\nehem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\core\\typed_passes.py:326: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see https://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 397:\u001b[0m\n",
      "\u001b[1mdef data_gen(size, p):\n",
      "    <source elided>\n",
      "    test_array = np.zeros((size, 2), dtype = np.int)\n",
      "\u001b[1m    for i in range(size):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaPerformanceWarning(msg,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [3, 0],\n",
       "       [4, 0],\n",
       "       [5, 0],\n",
       "       [6, 0],\n",
       "       [7, 0],\n",
       "       [8, 1],\n",
       "       [9, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "fbtk.data_gen(size = 10, p = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventional Test\n",
    "\n",
    "`conventional_test` gives the test results to a subject array given the probability of a type II error, the probability of a type I error, the number of repetition, and setting of sequence testing or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nehem\\AppData\\Local\\Temp/ipykernel_8516/1000256752.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  subject_array = fbtk.data_gen(10, 0.1)\n",
      "C:\\Users\\nehem\\Documents\\programming\\batch-testing\\batch_testing\\fast_btk.py:10: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"conventional_test\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function zeros>) found for signature:\n",
      " \n",
      " >>> zeros(UniTuple(int64 x 2), dtype=Function(<class 'int'>))\n",
      " \n",
      "There are 2 candidate implementations:\n",
      "\u001b[1m      - Of which 2 did not match due to:\n",
      "      Overload of function 'zeros': File: numba\\core\\typing\\npydecl.py: Line 511.\n",
      "        With argument(s): '(UniTuple(int64 x 2), dtype=Function(<class 'int'>))':\u001b[0m\n",
      "\u001b[1m       No match.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: resolving callee type: Function(<built-in function zeros>)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of call at C:\\Users\\nehem\\Documents\\programming\\batch-testing\\batch_testing\\fast_btk.py (40)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 40:\u001b[0m\n",
      "\u001b[1mdef conventional_test(subject_array, typeII_error, typeI_error, repeat = 1,\n",
      "    <source elided>\n",
      "        \n",
      "\u001b[1m        test_result = np.zeros(subject_array.shape, dtype = np.int)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "C:\\Users\\nehem\\Documents\\programming\\batch-testing\\batch_testing\\fast_btk.py:10: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"conventional_test\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 38:\u001b[0m\n",
      "\u001b[1mdef conventional_test(subject_array, typeII_error, typeI_error, repeat = 1,\n",
      "    <source elided>\n",
      "    if seq == True:\n",
      "\u001b[1m        consum = 0\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "c:\\users\\nehem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"conventional_test\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 37:\u001b[0m\n",
      "\u001b[1mdef conventional_test(subject_array, typeII_error, typeI_error, repeat = 1,\n",
      "    <source elided>\n",
      "    # Sequential Testing\n",
      "\u001b[1m    if seq == True:\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\users\\nehem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 37:\u001b[0m\n",
      "\u001b[1mdef conventional_test(subject_array, typeII_error, typeI_error, repeat = 1,\n",
      "    <source elided>\n",
      "    # Sequential Testing\n",
      "\u001b[1m    if seq == True:\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\nehem\\Documents\\programming\\batch-testing\\batch_testing\\fast_btk.py:10: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"conventional_test\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function zeros>) found for signature:\n",
      " \n",
      " >>> zeros(UniTuple(int64 x 2), dtype=Function(<class 'int'>))\n",
      " \n",
      "There are 2 candidate implementations:\n",
      "\u001b[1m      - Of which 2 did not match due to:\n",
      "      Overload of function 'zeros': File: numba\\core\\typing\\npydecl.py: Line 511.\n",
      "        With argument(s): '(UniTuple(int64 x 2), dtype=Function(<class 'int'>))':\u001b[0m\n",
      "\u001b[1m       No match.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: resolving callee type: Function(<built-in function zeros>)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of call at C:\\Users\\nehem\\Documents\\programming\\batch-testing\\batch_testing\\fast_btk.py (40)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 40:\u001b[0m\n",
      "\u001b[1mdef conventional_test(subject_array, typeII_error, typeI_error, repeat = 1,\n",
      "    <source elided>\n",
      "        \n",
      "\u001b[1m        test_result = np.zeros(subject_array.shape, dtype = np.int)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit(parallel = True)\n",
      "c:\\users\\nehem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"conventional_test\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 38:\u001b[0m\n",
      "\u001b[1mdef conventional_test(subject_array, typeII_error, typeI_error, repeat = 1,\n",
      "    <source elided>\n",
      "    if seq == True:\n",
      "\u001b[1m        consum = 0\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\users\\nehem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"fast_btk.py\", line 38:\u001b[0m\n",
      "\u001b[1mdef conventional_test(subject_array, typeII_error, typeI_error, repeat = 1,\n",
      "    <source elided>\n",
      "    if seq == True:\n",
      "\u001b[1m        consum = 0\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n",
      "test consumption 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nehem\\AppData\\Local\\Temp/ipykernel_8516/1000256752.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_result, consum = fbtk.conventional_test(subject_array, typeII_error = 0.15,\n"
     ]
    }
   ],
   "source": [
    "subject_array = fbtk.data_gen(10, 0.1)\n",
    "test_result, consum = fbtk.conventional_test(subject_array, typeII_error = 0.15,\n",
    "typeI_error=0.01, repeat= 1)\n",
    "print(f'accuracy: {np.mean(subject_array[:,1] == test_result[:,1])}')\n",
    "print(f'test consumption {consum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-step Batch Testing\n",
    "\n",
    "`seq_test` gives the test results to a subject array, the total number of \n",
    "test-kit consumption, and the number of individual tests given the subject array,\n",
    "stopping rule, batch size, probability of a type II error, probability of a Type I error, and the number of repetition, probability threshold, and \n",
    "setting of sequence testing or not.\n",
    "\n",
    "The following code will generate a population with size 100000 and the infection rate of 0.01. The setting of this multi-step batch testing is up to 3 sequential individual tests for 3 batch positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nehem\\AppData\\Local\\Temp/ipykernel_8516/3946128192.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  subject_array = fbtk.data_gen(100000, 0.01)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'fast_btk' has no attribute 'one_batch_test_int_solver'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8516/3946128192.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msubject_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfbtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfbtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_batch_test_int_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfbtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_batch_test_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind_consum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfbtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstop_rule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypeII_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypeI_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'fast_btk' has no attribute 'one_batch_test_int_solver'"
     ]
    }
   ],
   "source": [
    "subject_array = fbtk.data_gen(100000, 0.01)\n",
    "print(fbtk.one_batch_test_solver(0.01, 0.15, 0.01))\n",
    "batch_size = fbtk.one_batch_test_solver(0.01, 0.15, 0.01)\n",
    "print(batch_size)\n",
    "test_result, consum, ind_consum = fbtk.seq_test(subject_array, batch_size = batch_size,stop_rule = 3,p = 0.01, typeII_error = 0.15, typeI_error=0.01, repeat= 3, seq = True)\n",
    "print(f'accuracy: {np.mean(subject_array[:,1] == test_result[:,1])}')\n",
    "print(f'test consumption {consum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Results\n",
    "\n",
    "The following code is to produce results on Table 7 and Table 8. We will go through table 7_(a) and show the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 7 (a)\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    length = len(temp_data)\n",
    "    acc = np.zeros(length)\n",
    "    sens = np.zeros(length)\n",
    "    spec = np.zeros(length)\n",
    "    ppv = np.zeros(length)\n",
    "    npv = np.zeros(length)\n",
    "    test_consum = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        pred, consum = fbtk.conventional_test(temp_data[i], typeII_error= 0.15, typeI_error=0.01)\n",
    "        acc[i] = np.mean(pred[:,1] == temp_data[i][:, 1])\n",
    "        sens[i] = recall_score(temp_data[i][:, 1], pred[:, 1])\n",
    "        spec[i] = fbtk.specificity_score(temp_data[i][:, 1], pred[:, 1])\n",
    "        ppv[i] = precision_score(temp_data[i][:, 1], pred[:, 1])\n",
    "        npv[i] = fbtk.npv_score(temp_data[i][:, 1], pred[:, 1])\n",
    "        test_consum[i] = consum\n",
    "    result = {\n",
    "        'acc': acc,\n",
    "        'sens': sens,\n",
    "        'spec': spec,\n",
    "        'PPV': ppv,\n",
    "        'NPV': npv,\n",
    "        'test_consum': test_consum\n",
    "    \n",
    "    }\n",
    "    result = pd.DataFrame(result)\n",
    "    result_mean = result.mean()\n",
    "    result_std = result.std()\n",
    "    temp_df = [prob, result_mean['acc'], result_std['acc'], result_mean['sens'], result_std['sens'],\n",
    "    result_mean['spec'], result_std['spec'], result_mean['PPV'], result_std['PPV'], result_mean['NPV'],\n",
    "    result_std['NPV'], result_mean['test_consum'], result_std['test_consum']]\n",
    "    temp_df = pd.DataFrame(temp_df)\n",
    "    temp_df = temp_df.T\n",
    "    temp_df.columns = df.columns\n",
    "    df = pd.concat([df, temp_df])\n",
    "\n",
    "\n",
    "  \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For table 7 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 7 (b)\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [1]:\n",
    "            for k in [1]:\n",
    "                \n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': 10,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('table7_b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For table 7 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(10000, prob) for _ in range(10)]\n",
    "    for i in [True]:\n",
    "        for j in [1]:\n",
    "            for k in [3]:\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.15, 0.01, batch_limit= 32)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i, 'batch_limit': 32}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 7 d\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sq_Repeat', 'Ind_Repeat', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [3]: # sq_repeat\n",
    "        for j in [3]: # ind_repeat\n",
    "            kwargs = {\n",
    "                'side_length': 12,\n",
    "                'typeII_error': 0.15,\n",
    "                'typeI_error': 0.01,\n",
    "                'sq_repeat': i,\n",
    "                'ind_repeat': j\n",
    "            }\n",
    "            test_1 = fbtk.test_result(temp_data, fbtk.matrix_test, **kwargs)\n",
    "            temp_mean = test_1.mean()\n",
    "            temp_std = test_1.std()\n",
    "            temp = [prob, kwargs['sq_repeat'], kwargs['ind_repeat'], temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "            temp_df = pd.DataFrame(temp)\n",
    "            temp_df = temp_df.T\n",
    "            temp_df.columns = ['Infection_rate', 'Sq_Repeat', 'Ind_Repeat', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "            df = pd.concat([df, temp_df])\n",
    "\n",
    "            \n",
    "                \n",
    "               \n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table 7 (E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [1]: # repeat\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.15, 0.01)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('table7_e.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table 7 (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [3]: # repeat\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.15, 0.01, batch_limit= 32)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i, 'batch_limit': 32}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('table7_f_limit_32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [3]: # repeat\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.15, 0.01, batch_limit= 64)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i, 'batch_limit': 64}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('table7_f_limit_64.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [2]: # stop_rule\n",
    "            for k in [2]: # repeat\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.15, 0.01, batch_limit= 32)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i, 'batch_limit': 32}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('stop_rule_2_limit_32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [2]: # stop_rule\n",
    "            for k in [2]: # repeat\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.15, 0.01, batch_limit= 64)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i, 'batch_limit': 64} # change batch_limt\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')\n",
    "df.to_csv('stop_rule_2_limit_64.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appendix A\n",
    "# table 7 (a)\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    length = len(temp_data)\n",
    "    acc = np.zeros(length)\n",
    "    sens = np.zeros(length)\n",
    "    spec = np.zeros(length)\n",
    "    ppv = np.zeros(length)\n",
    "    npv = np.zeros(length)\n",
    "    test_consum = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        pred, consum = fbtk.conventional_test(temp_data[i], typeII_error= 0.25, typeI_error=0.03)\n",
    "        acc[i] = np.mean(pred[:,1] == temp_data[i][:, 1])\n",
    "        sens[i] = recall_score(temp_data[i][:, 1], pred[:, 1])\n",
    "        spec[i] = fbtk.specificity_score(temp_data[i][:, 1], pred[:, 1])\n",
    "        ppv[i] = precision_score(temp_data[i][:, 1], pred[:, 1])\n",
    "        npv[i] = fbtk.npv_score(temp_data[i][:, 1], pred[:, 1])\n",
    "        test_consum[i] = consum\n",
    "    result = {\n",
    "        'acc': acc,\n",
    "        'sens': sens,\n",
    "        'spec': spec,\n",
    "        'PPV': ppv,\n",
    "        'NPV': npv,\n",
    "        'test_consum': test_consum\n",
    "    \n",
    "    }\n",
    "    result = pd.DataFrame(result)\n",
    "    result_mean = result.mean()\n",
    "    result_std = result.std()\n",
    "    temp_df = [prob, result_mean['acc'], result_std['acc'], result_mean['sens'], result_std['sens'],\n",
    "    result_mean['spec'], result_std['spec'], result_mean['PPV'], result_std['PPV'], result_mean['NPV'],\n",
    "    result_std['NPV'], result_mean['test_consum'], result_std['test_consum']]\n",
    "    temp_df = pd.DataFrame(temp_df)\n",
    "    temp_df = temp_df.T\n",
    "    temp_df.columns = df.columns\n",
    "    df = pd.concat([df, temp_df])\n",
    "\n",
    "\n",
    "  \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('appendix_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix (b)\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [1]:\n",
    "            for k in [1]:\n",
    "                \n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': 10,\n",
    "                'typeII_error': 0.25, 'typeI_error': 0.03, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('appendix_b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix (c)\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [1]:\n",
    "            for k in [3]:\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.25, 0.03)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.25, 'typeI_error': 0.03, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('appendix_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix (d)\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sq_Repeat', 'Ind_Repeat', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [3]: # sq_repeat\n",
    "        for j in [3]: # ind_repeat\n",
    "            kwargs = {\n",
    "                'side_length': 12,\n",
    "                'typeII_error': 0.25,\n",
    "                'typeI_error': 0.03,\n",
    "                'sq_repeat': i,\n",
    "                'ind_repeat': j\n",
    "            }\n",
    "            test_1 = fbtk.test_result(temp_data, fbtk.matrix_test, **kwargs)\n",
    "            temp_mean = test_1.mean()\n",
    "            temp_std = test_1.std()\n",
    "            temp = [prob, kwargs['sq_repeat'], kwargs['ind_repeat'], temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "            temp_df = pd.DataFrame(temp)\n",
    "            temp_df = temp_df.T\n",
    "            temp_df.columns = ['Infection_rate', 'Sq_Repeat', 'Ind_Repeat', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "            df = pd.concat([df, temp_df])\n",
    "\n",
    "            \n",
    "                \n",
    "               \n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('appendix_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix e\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [1]: # repeat\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.25, 0.03)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.25, 'typeI_error': 0.03, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix f\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [3]: # repeat\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.25, 0.03)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.25, 'typeI_error': 0.03, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': i}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['seq'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Sequential_test', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ''\n",
    "str.count(string, '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_fun(n, string = ''):\n",
    "    if str.count(string, '+') >= n or str.count(string, '-') >= n:\n",
    "        return string\n",
    "    else:\n",
    "        next_string = string + '+'\n",
    "        return helper_fun(n, next_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_fun(n):\n",
    "    \"\"\"\n",
    "    input: stopping rule\n",
    "    output: finish nodes\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    temp = ['']\n",
    "    for i in range(2*n-1):\n",
    "        temp_cur = []\n",
    "        for j in temp:\n",
    "            candidate_pos = j + '+'\n",
    "            candidate_neg = j + '-'\n",
    "            if str.count(candidate_pos, '+') >= n:\n",
    "                output.append(candidate_pos)\n",
    "            else:\n",
    "                temp_cur.append(candidate_pos)\n",
    "\n",
    "            if str.count(candidate_neg, '-') >= n:\n",
    "                output.append(candidate_neg)\n",
    "            else:\n",
    "                temp_cur.append(candidate_neg)\n",
    "\n",
    "        temp = temp_cur\n",
    "\n",
    "        neg_symbol = [x for x in output if str.count(x, '-') == n]\n",
    "        pos_symbol = [x for x in output if str.count(x, '+') == n]\n",
    "\n",
    "    return output, neg_symbol, pos_symbol\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = name_fun(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-0.15) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([(1-0.15) ** 3 * (1-0.15 ** 3) * binom(2+i, i) * 0.15 ** i for i in range(0, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-0.15) ** 2 * (1 - 0.15 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(n, beta):\n",
    "    _, _, pos_node = name_fun(n)\n",
    "    res = [(1-beta) * (1-beta) ** i.count('+') * beta ** (i.count('-')) for i in pos_node]\n",
    "    return sum(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "output = []\n",
    "temp = ['']\n",
    "for i in range(2*n-1):\n",
    "    temp_cur = []\n",
    "    for j in temp:\n",
    "        candidate_pos = j + '+'\n",
    "        candidate_neg = j + '-'\n",
    "        if str.count(candidate_pos, '+') >= n:\n",
    "            output.append(candidate_pos)\n",
    "        else:\n",
    "            temp_cur.append(candidate_pos)\n",
    "\n",
    "        if str.count(candidate_neg, '-') >= n:\n",
    "            output.append(candidate_neg)\n",
    "        else:\n",
    "            temp_cur.append(candidate_neg)\n",
    "\n",
    "    temp = temp_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fbtk.data_gen(100000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, e = fbtk.seq_test_with_node(temp,stop_rule = 3,p = 0.1, batch_size = 32, typeII_error = 0.15, typeI_error = 0.01, repeat = 1, \n",
    "prob_threshold = 0.3, seq = True, batch_limit = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 > np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_summary(data, seq_test, stopping_rule, **kwargs):\n",
    "    a, _, _ = fbtk.name_fun(stopping_rule)\n",
    "    a.extend(['other'])\n",
    "    df = pd.DataFrame([], columns = a)\n",
    "    b = ['stage_' + str(i) for i in range(1, 2*stopping_rule)]\n",
    "    df_b = pd.DataFrame([], columns = b)\n",
    "    if not isinstance(data, list):\n",
    "        _, _, _, node, batch_list = seq_test(data, **kwargs)\n",
    "        temp = np.zeros(len(a))\n",
    "        node_count = collections.Counter(node)\n",
    "        for i in node_count:\n",
    "            if i in a:\n",
    "                idx = a.index(i)\n",
    "                temp[idx] = node_count[i]\n",
    "            else:\n",
    "                temp[-1] += node_count[i]\n",
    "        df.loc[len(df)] = temp\n",
    "        df_b.loc[len(df)] = batch_list\n",
    "\n",
    "        return df, df_b\n",
    "\n",
    "    else:\n",
    "        for j in range(len(data)):\n",
    "            _, _, _, node, batch_list = seq_test(data[j], **kwargs)\n",
    "            temp = np.zeros(len(a))\n",
    "            node_count = collections.Counter(node)\n",
    "            for i in node_count:\n",
    "                if i in a:\n",
    "                    idx = a.index(i)\n",
    "                    temp[idx] = node_count[i]\n",
    "                else:\n",
    "                    temp[-1] += node_count[i]\n",
    "            df.loc[len(df)] = temp\n",
    "            df_b.loc[len(df)] = batch_list\n",
    "\n",
    "\n",
    "        return df, df_b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.1\n",
    "k = 10000000\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "data = fbtk.data_gen(100000, s)\n",
    "a,b, c, d, e, = fbtk.seq_test_with_node(data, 3, 0.1,32, 0.15, 0.01, 3, 0.3, batch_limit=k)\n",
    "a1, b1, c1 = fbtk.seq_test(data, 3, 0.1, 32, 0.15, 0.01, 3, 0.3, seq = True, batch_limit = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(a[:,1] == data[:,1])\n",
    "#print(b, b1, c, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "node_name,_,_ = fbtk.name_fun(3)\n",
    "result = pd.DataFrame([], columns=node_name.extend(['p', 'stop_rule', 'upper limit']))\n",
    "col_b = ['stage_' + str(i) for i in range(1, 2*3)]\n",
    "col_b.extend(['p', 'stop_rule', 'upper limit'])\n",
    "\n",
    "result_b = pd.DataFrame([], columns = col_b)\n",
    "for s in [0.001, 0.01, 0.03, 0.05, 0.1]:\n",
    "    temp_data = [fbtk.data_gen(100000, s) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [32, 64, 1000000]: # batch_upperlimit\n",
    "                batch_size = fbtk.one_batch_test_int_solver(s, 0.15, 0.01, batch_limit= k)\n",
    "                kwargs = {'stop_rule': j, 'p': s, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': 3,\n",
    "                'prob_threshold': 0.3, 'seq': i, 'batch_limit': k}\n",
    "                test, test_b = node_summary(temp_data, fbtk.seq_test_with_node,j,**kwargs)\n",
    "                test['p'] = s\n",
    "                test['stop_rule'] = 3\n",
    "                test['upper limit'] = k\n",
    "                test_b['p'] = s\n",
    "                test_b['stop_rule'] = 3\n",
    "                test_b['p'] = s\n",
    "                test_b['upper limit'] = k\n",
    "                result = pd.concat([result, test])\n",
    "                result_b = pd.concat([result_b, test_b])\n",
    "\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "node_name,_,_ = fbtk.name_fun(3)\n",
    "result = pd.DataFrame([], columns=node_name.extend(['p', 'stop_rule', 'upper limit']))\n",
    "col_b = ['stage_' + str(i) for i in range(1, 2*3)]\n",
    "col_b.extend(['p', 'stop_rule', 'upper limit'])\n",
    "\n",
    "result_b = pd.DataFrame([], columns = col_b)\n",
    "for s in [0.001, 0.01, 0.03]:\n",
    "    temp_data = [fbtk.data_gen(100000, s) for _ in range(1000)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [1000000]: # batch_upperlimit\n",
    "                batch_size = fbtk.one_batch_test_int_solver(s, 0.15, 0.01, batch_limit= k)\n",
    "                kwargs = {'stop_rule': j, 'p': s, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': 3,\n",
    "                'prob_threshold': 1, 'seq': i, 'batch_limit': k}\n",
    "                test, test_b = node_summary(temp_data, fbtk.seq_test_with_node,j,**kwargs)\n",
    "                test['p'] = s\n",
    "                test['stop_rule'] = 3\n",
    "                test['upper limit'] = k\n",
    "                test_b['p'] = s\n",
    "                test_b['stop_rule'] = 3\n",
    "                test_b['p'] = s\n",
    "                test_b['upper limit'] = k\n",
    "                result = pd.concat([result, test])\n",
    "                result_b = pd.concat([result_b, test_b])\n",
    "\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('more_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('node_test.csv')\n",
    "result_b.to_csv('batch_cum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "node_name,_,_ = fbtk.name_fun(3)\n",
    "result = pd.DataFrame([], columns=node_name.extend(['p', 'stop_rule', 'upper limit']))\n",
    "for s in [0.001, 0.01, 0.03, 0.05, 0.1]:\n",
    "    temp_data = [fbtk.data_gen(100000, s) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [32, 64, 1000000]: # batch_upperlimit\n",
    "                batch_size = fbtk.one_batch_test_int_solver(s, 0.15, 0.01, batch_limit= k)\n",
    "                kwargs = {'stop_rule': j, 'p': s, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': 3,\n",
    "                'prob_threshold': 1, 'seq': i, 'batch_limit': k}\n",
    "                test = node_summary(temp_data, fbtk.seq_test_with_node,j,**kwargs)\n",
    "                test['p'] = s\n",
    "                test['stop_rule'] = 3\n",
    "                test['upper limit'] = k\n",
    "                result = pd.concat([result, test])\n",
    "\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('node_test_without_threshold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros(21)\n",
    "\n",
    "for item in test:\n",
    "    if item in a:\n",
    "        idx = a.index(item)\n",
    "        temp[idx] = test[item]\n",
    "    else:\n",
    "        temp[-1] += test[item]\n",
    "df.loc[len(df)] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(collections.Counter(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.Counter(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "node_name,_,_ = fbtk.name_fun(3)\n",
    "result = pd.DataFrame([], columns=node_name.extend(['p', 'stop_rule', 'upper limit']))\n",
    "for s in [0.001, 0.01, 0.03, 0.05, 0.1]:\n",
    "    temp_data = [fbtk.data_gen(100000, s) for _ in range(100)]\n",
    "    for i in [True]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [32, 64, 1000000]: # batch_upperlimit\n",
    "                batch_size = fbtk.one_batch_test_int_solver(s, 0.15, 0.01, batch_limit= k)\n",
    "                kwargs = {'stop_rule': j, 'p': s, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': 3,\n",
    "                'prob_threshold': 1, 'seq': i, 'batch_limit': k}\n",
    "                test = node_summary(temp_data, fbtk.seq_test_with_node,j,**kwargs)\n",
    "                test['p'] = s\n",
    "                test['stop_rule'] = 3\n",
    "                test['upper limit'] = k\n",
    "                result = pd.concat([result, test])\n",
    "\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix f\n",
    "time_start = time.time()\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame([], columns = ['Infection_rate', 'Batch_upper_limit', 'Stop_rule', 'Repeat', 'Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD'])\n",
    "for prob in [0.001, 0.01, 0.03, 0.05, 0.10]:\n",
    "    temp_data = [fbtk.data_gen(100000, prob) for _ in range(100)]\n",
    "    for i in [32, 64, 100000]:\n",
    "        for j in [3]: # stop_rule\n",
    "            for k in [3]: # repeat\n",
    "                batch_size = fbtk.one_batch_test_int_solver(prob, 0.15, 0.01, batch_limit = i)\n",
    "                kwargs = {'stop_rule': j, 'p': prob, 'batch_size': batch_size,\n",
    "                'typeII_error': 0.15, 'typeI_error': 0.01, 'repeat': k,\n",
    "                'prob_threshold': 0.3, 'seq': True, 'batch_limit': i}\n",
    "                test_1 = fbtk.test_result(temp_data, fbtk.seq_test, **kwargs)\n",
    "                temp_mean = test_1.mean()\n",
    "                temp_std = test_1.std()\n",
    "                temp = [kwargs['p'], kwargs['batch_limit'], kwargs['stop_rule'], kwargs['repeat'], kwargs['prob_threshold'],temp_mean['acc'], temp_std['acc'], temp_mean['sens'], temp_std['sens'], temp_mean['spec'], temp_std['spec'], temp_mean['PPV'], temp_std['PPV'], temp_mean['NPV'], temp_std['NPV'], temp_mean['test_consum'], temp_std['test_consum'], temp_mean['ind_consum'], temp_std['ind_consum'], temp_mean['batch_consum'], temp_std['batch_consum']]\n",
    "                temp_df = pd.DataFrame(temp)\n",
    "                temp_df = temp_df.T\n",
    "                temp_df.columns = ['Infection_rate', 'Batch_upper_limit', 'Stop_rule', 'Repeat','Prob_threshold', 'Acc', 'Acc_SD', 'Sens', 'Sens_SD', 'Spec','Spec_SD','PPV', 'PPV_SD',\n",
    "    'NPV', 'NPV_SD', 'Test_consum', 'Test_consum_SD', 'Ind_consum', 'Ind_consum_SD', 'Batch_consum','Batch_consum_SD']\n",
    "                df = pd.concat([df, temp_df])\n",
    "            \n",
    "time_end = time.time()\n",
    "print('running time:', time_end - time_start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result_batch_limit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbtk.one_batch_test_int_solver(0.05, 0.15, 0.01, batch_limit = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?fbtk.one_batch_test_int_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[2,-2,0],[1, 0, -1],[0, 1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[2, 4, 6, 8],[1, 2, 3, 4], [3, 5, 7, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(np.matmul(B, A) , np.array([[1],[-1], [1], [0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
